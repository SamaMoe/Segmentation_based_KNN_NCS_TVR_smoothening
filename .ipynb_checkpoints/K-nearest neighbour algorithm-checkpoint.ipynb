{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Notebook for chromatogram denoising using k-nearest neighbour algorithm with chromatogram segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn import neighbors\n",
    "import math\n",
    "from itertools import islice\n",
    "from joblib import Parallel, delayed\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open excel\n",
    "# extract first column as time and second as signal\n",
    "# file (string) = path to excel file\n",
    "# sheet (string) = name of excel sheet\n",
    "def open_chrom_xlsx(file, sheet):\n",
    "    if type(file) != str:\n",
    "        print(\"path must be a string\")\n",
    "    if type(sheet) != str:\n",
    "        print(\"sheet must be a string\")\n",
    "    df = pd.read_excel(file, sheet_name= sheet)\n",
    "    df.columns=(['time','abs'])\n",
    "    time = list(df['time'])\n",
    "    abs = list(df['abs'])\n",
    "    return time,abs\n",
    "\n",
    "#compute mean of a list\n",
    "# l (list) = numerical list (len > 0)\n",
    "def mean(l):\n",
    "    if len(l) < 1:\n",
    "        print(\"list must have length higher than 0\")\n",
    "    else:\n",
    "        s = sum(l)\n",
    "        l = len(l)\n",
    "        avr = s/l\n",
    "    return avr\n",
    "\n",
    "# k-nearest neighbors\n",
    "# x (list) = time axis or number of datapoints\n",
    "# y (list) = signal\n",
    "# n_neighbors (odd int) = number of neighbors (must be odd)\n",
    "def knearestneighbor(n_neighbors,x,y):\n",
    "    if n_neighbors < 1 or n_neighbors%2 == 0:\n",
    "        print(\"number of neighbors must be a positive odd integer value\")\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=\"uniform\")\n",
    "    pred = knn.fit(x, y).predict(x)\n",
    "    return pred\n",
    "\n",
    "# Durbin Watson criterion\n",
    "#expLine (list) = experimental signal\n",
    "#smtLine (list) = denoised line\n",
    "def DWcrit(expLine,smtLine):\n",
    "    if len(expLine) != len(smtLine):\n",
    "        print(\"experimental and smoothened signal must have same length\")\n",
    "    num = 0\n",
    "    denum = 0\n",
    "    for i in range(len(expLine)):\n",
    "        denum = denum + (expLine[i]-smtLine[i])**2\n",
    "    for j in range(len(expLine)-1):\n",
    "        num = num + ((expLine[j+1]-smtLine[j+1])-(expLine[j]-smtLine[j]))**2\n",
    "    DW = num/denum\n",
    "    fac = len(expLine) / (len(expLine) - 1)\n",
    "    DWfac = DW * fac\n",
    "    return DWfac\n",
    "\n",
    "# segment signal in groups of n\n",
    "# l = signal\n",
    "# n = number of elements in segment\n",
    "def chunk(l, n):\n",
    "    if type(n) != int or n < 1:\n",
    "        print(\"number of elements must be a positve integer higher than 1\")\n",
    "    n = max(1, n)\n",
    "    return list((l[i:i+n] for i in range(0, len(l), n)))\n",
    "\n",
    "# group segments together to form peak blocks and inter-peak blocks\n",
    "# seg (list of lists) = list of lists storing signal segmented into groups\n",
    "# thresh (float) = threshold used to classify segment as peak or inter-peak segment\n",
    "def grouping(seg,thresh):\n",
    "    groups = []\n",
    "    while len(seg) > 1:\n",
    "        i = 0\n",
    "        init = seg[i]\n",
    "        block = []\n",
    "        block.append(init)\n",
    "        if mean(init) <= thresh:\n",
    "            while mean(seg[i+1]) <= thresh:\n",
    "                block.append(seg[i + 1])\n",
    "                if i + 1 == len(seg)-1:\n",
    "                    break\n",
    "                else:\n",
    "                    i = i + 1\n",
    "\n",
    "        if mean(init) > thresh:\n",
    "            while mean(seg[i+1])>thresh:\n",
    "                block.append(seg[i + 1])\n",
    "                if i + 1 == len(seg) - 1:\n",
    "                    break\n",
    "                else:\n",
    "                    i = i + 1\n",
    "        lst = [x for l in block for x in l]\n",
    "        groups.append(lst)\n",
    "        seg = seg[i+1:]\n",
    "\n",
    "    return groups\n",
    "\n",
    "# smoothing of inter section\n",
    "# groups (list of lists) = list of lists storing the peak and inter-peak segments\n",
    "def smooth_inter(groups):\n",
    "    for i in range(len(groups)-1):\n",
    "        n = min(3,min(int(len(groups[i])/3),int(len(groups[i+1])/3)))\n",
    "        last = groups[i][-n:].tolist()\n",
    "        first = groups[i+1][:n].tolist()\n",
    "        last.extend(first)\n",
    "        x = np.linspace(0,1,len(last))\n",
    "        #pred = polyreg(x,last,2)\n",
    "        # if len(last)%2 != 0:\n",
    "        #     nei = len(last)\n",
    "        # else:\n",
    "        #     nei = len(last) - 1\n",
    "        pred = knearestneighbor(3,np.transpose([np.linspace(0, 1, len(last))]),last)\n",
    "        groups[i][-n:] = pred[:n]\n",
    "        groups[i + 1][:n] = pred[-n:]\n",
    "\n",
    "    return groups\n",
    "\n",
    "# function to find optimal smoothing using k-nearest neighbour\n",
    "# segment (list) = signal segment that needs to be optimally smoothened\n",
    "# thresh (float) = threshold classifying segment as peak or inter-peak segment\n",
    "def segment_smooth_knearest(segment,thresh):\n",
    "    DW_crit = []\n",
    "    initial = 0\n",
    "    if mean(segment) < thresh:\n",
    "        if int(len(segment)/10)%2 == 0:\n",
    "            initial = int(len(segment)/10) + 1\n",
    "        else :\n",
    "            initial = int(len(segment)/10)\n",
    "        if len(segment) > 500:\n",
    "            nei = np.arange(initial,len(segment),50)\n",
    "        else:\n",
    "            nei = np.arange(initial,len(segment),10)\n",
    "        for n in nei:\n",
    "            p = knearestneighbor(n, np.transpose([np.linspace(0, 1, len(segment))]), segment)\n",
    "            crit = (2.0 - DWcrit(segment, p)) ** 2\n",
    "            DW_crit.append(crit)\n",
    "    else:\n",
    "        initial = 5\n",
    "        nei = np.arange(initial, int(len(segment)/3), 2)\n",
    "        for n in nei:\n",
    "            p = knearestneighbor(n, np.transpose([np.linspace(0, 1, len(segment))]), segment)\n",
    "            crit = (2.0 - DWcrit(segment, p)) ** 2\n",
    "            DW_crit.append(crit)\n",
    "    if (len(DW_crit) == 0):\n",
    "        smooth = knearestneighbor(int(len(segment)/4), np.transpose([np.linspace(0, 1, len(segment))]), segment)\n",
    "    else:\n",
    "        val, idx = min((val, idx) for (idx, val) in enumerate(DW_crit))\n",
    "        smooth = knearestneighbor(nei[idx], np.transpose([np.linspace(0, 1, len(segment))]), segment)\n",
    "\n",
    "    return smooth\n",
    "\n",
    "#computes baseline of signal\n",
    "# func (list) = signal\n",
    "def baseline(func):\n",
    "    l = []\n",
    "    for i in range(len(func)-2):\n",
    "        m = (math.fabs(func[i+1]-func[i]) + math.fabs(func[i+1] - func[i+2])) / 2\n",
    "        l.append(m)\n",
    "    med = statistics.median(l)\n",
    "    return med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of KNN on experimental chromatogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_noisy = np.load(\"./constructed7.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## segmentation\n",
    "seg = chunk(c_noisy,10)\n",
    "## grouping ##\n",
    "groups = grouping(seg, baseline(c_noisy)*2)\n",
    "\n",
    "####################\n",
    "#k-nearest neighbor#\n",
    "####################\n",
    "\n",
    "smoothing = Parallel(n_jobs=3)(delayed(segment_smooth_knearest)(g,max(c_noisy)/10) for g in groups)\n",
    "lst = [x for l in smoothing for x in l]\n",
    "groups = smooth_inter(smoothing)\n",
    "lst = [x for l in groups for x in l]\n",
    "\n",
    "plt.plot(c_noisy, color = \"saddlebrown\")\n",
    "plt.plot(lst)\n",
    "plt.title(\"Segmentation-based k-nearest neighbors\")\n",
    "plt.legend((\"noisy chromatogram\",\"smoothed chromatogram\"))\n",
    "plt.ylabel(\"Absorbance\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.tick_params(axis='x', labelsize=14)\n",
    "plt.tick_params(axis='y', labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
